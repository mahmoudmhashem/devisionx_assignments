{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Batch normalization Task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# define some helper classes helps me in my code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Any\n",
    "\n",
    "\n",
    "class MyMean():\n",
    "    def __call__(self, X, axis=0) -> np.ndarray:\n",
    "        return self.forward(X, axis=0)\n",
    "\n",
    "    def forward(self, X, axis=0) -> np.ndarray:\n",
    "        self.M = X.shape[:axis+1]\n",
    "        self.N = X.shape[axis+1:]\n",
    "        self.axis = axis\n",
    "        out = np.sum(X, axis=axis) / self.M\n",
    "        return out\n",
    "\n",
    "    def backward(self, dz) -> np.ndarray:\n",
    "        dz = np.asarray(dz)\n",
    "        assert dz.shape == self.N, \"dz shape doesn't equal the number of features passed in forward propagation\"\n",
    "        dz = np.atleast_2d(dz)\n",
    "        dout = np.repeat(dz, self.M, self.axis) / self.M\n",
    "        return dout\n",
    "\n",
    "class MyPow():\n",
    "    def __init__(self, x, pow=2) -> None:\n",
    "        self.x = x\n",
    "        self.pow = pow\n",
    "\n",
    "    def __call__(self):\n",
    "        return self.forward()\n",
    "    def forward(self):\n",
    "        return self.x**self.pow\n",
    "\n",
    "    def backward(self, dout):\n",
    "        dout = dout * self.pow * self.x**(self.pow-1)\n",
    "        return dout\n",
    "\n",
    "class MyBroadcasting:\n",
    "    def __call__(self, x:np.ndarray, shape:int) -> np.ndarray:\n",
    "        return self.forward(x, shape)\n",
    "\n",
    "    def forward(self, x:np.ndarray, shape:tuple):\n",
    "        self.shape = shape\n",
    "        out = np.broadcast_to(x, shape)\n",
    "        return out\n",
    "\n",
    "    def backward(self, dz:np.ndarray):\n",
    "        assert dz.shape == self.shape, \"dz shape doesn't equal the shape of z passed in forward propagation\"\n",
    "        dz = np.sum(dz, axis=0)\n",
    "        return dz\n",
    "\n",
    "class Center:\n",
    "    def __init__(self) -> None:\n",
    "        self.mymean = MyMean()\n",
    "        self.mybrod = MyBroadcasting()\n",
    "\n",
    "    def __call__(self, X, axis=0) -> Any:\n",
    "        return self.forward(X, axis=axis)\n",
    "\n",
    "    def forward(self, X, axis=0):\n",
    "        mu = self.mymean(X, axis)\n",
    "        mu_brod = self.mybrod(mu, X.shape)\n",
    "        x_centered = X - mu_brod\n",
    "        return x_centered\n",
    "    \n",
    "    def backward(self, dz):\n",
    "        dx1 = dz\n",
    "        dmu_brod = dz\n",
    "        dmu = self.mybrod.backward(dmu_brod)\n",
    "        dx2 = self.mymean.backward(dmu)\n",
    "        dx = dx1+dx2\n",
    "        return dx\n",
    "\n",
    "class Mul:\n",
    "    def __call__(self, x1, x2):\n",
    "        return self.forward(x1, x2)\n",
    "\n",
    "    def forward(self, x1, x2):\n",
    "        self.x1 = x1\n",
    "        self.x2 = x2\n",
    "        return x1 * x2\n",
    "    def backward(self, dz):\n",
    "        return dz*self.x1, dz*self.x2\n",
    "    \n",
    "class Sum:\n",
    "    def __call__(self, x1, x2):\n",
    "        return self.forward(x1, x2)\n",
    "\n",
    "    def forward(self, x1, x2):\n",
    "        self.x1 = x1\n",
    "        self.x2 = x2\n",
    "        return x1 + x2\n",
    "    def backward(self, dz):\n",
    "        return dz, dz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### define BatchNorm and BatchNormalization classes, my and tutorial's classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BatchNorm: # class of mine\n",
    "    def forward(self, x:np.ndarray, gamma, beta, eps):\n",
    "        M, N = x.shape\n",
    "        gamma , beta = np.array([gamma]), np.array([beta]*N)\n",
    "\n",
    "        self.center = Center() # \n",
    "        xmu = self.center(x)\n",
    "\n",
    "        self.pow2 = MyPow(xmu, 2) # \n",
    "        xmu2 = self.pow2()\n",
    "\n",
    "        self.mymean = MyMean() # \n",
    "        var = self.mymean(xmu2)\n",
    "\n",
    "        self.pow05 = MyPow(var+eps, 0.5) # \n",
    "        std = self.pow05()\n",
    "\n",
    "        self.pow_1 = MyPow(std, -1) # \n",
    "        istd = self.pow_1()\n",
    "\n",
    "        self.mybrod_istd = MyBroadcasting() # \n",
    "        istd_brod = self.mybrod_istd(istd, xmu.shape)\n",
    "\n",
    "        self.mul_norm = Mul() # \n",
    "        x_norm = self.mul_norm(xmu, istd_brod)\n",
    "\n",
    "        self.mybrod_gamma = MyBroadcasting() # \n",
    "        gamma_brod = self.mybrod_gamma(gamma, x_norm.shape)\n",
    "\n",
    "\n",
    "        self.mul_gamma = Mul() # \n",
    "        gamma_x_norm = self.mul_gamma(x_norm, gamma_brod)\n",
    "\n",
    "        self.mybrod_beta = MyBroadcasting() # \n",
    "        beta_brod = self.mybrod_beta(beta, gamma_x_norm.shape)\n",
    "\n",
    "        self.sum = Sum() # \n",
    "        out = self.sum(gamma_x_norm, beta_brod)\n",
    "\n",
    "        return out\n",
    "    \n",
    "    def backward(self, dout):\n",
    "        grad_gamma_x_norm, grad_beta_brod = self.sum.backward(dout)\n",
    "        grad_beta = self.mybrod_beta.backward(grad_beta_brod) # final\n",
    "\n",
    "        grad_x_norm, grad_gamma_brod = self.mul_gamma.backward(grad_gamma_x_norm)\n",
    "        grad_gamma = self.mybrod_gamma.backward(grad_gamma_brod) # final\n",
    "\n",
    "        grad_x1mu, grad_istd_brod = self.mul_norm.backward(grad_x_norm)\n",
    "        grad_istd = self.mybrod_istd.backward(grad_istd_brod)\n",
    "        grad_std = self.pow_1.backward(grad_istd)\n",
    "        grad_var = self.pow05.backward(grad_std)\n",
    "        grad_xmu2 = self.mymean.backward(grad_var)\n",
    "        grad_x2mu = self.pow2.backward(grad_xmu2)\n",
    "\n",
    "        grad_xmu = grad_x1mu + grad_x2mu\n",
    "        grad_x = self.center.backward(grad_xmu) # final\n",
    "\n",
    "        return grad_x, grad_gamma, grad_beta\n",
    "\n",
    "class BatchNormalization: # class of tutorial\n",
    "    def forward(self, x, gamma, beta, eps):\n",
    "        N, D = x.shape\n",
    "\n",
    "        #step1: calculate mean\n",
    "        mu = 1./N * np.sum(x, axis = 0)\n",
    "\n",
    "        #step2: subtract mean vector of every trainings example\n",
    "        xmu = x - mu\n",
    "\n",
    "        #step3: following the lower branch - calculation denominator\n",
    "        sq = xmu ** 2\n",
    "\n",
    "        #step4: calculate variance\n",
    "        var = 1./N * np.sum(sq, axis = 0)\n",
    "\n",
    "        #step5: add eps for numerical stability, then sqrt\n",
    "        sqrtvar = np.sqrt(var + eps)\n",
    "\n",
    "        #step6: invert sqrtwar\n",
    "        ivar = 1./sqrtvar\n",
    "\n",
    "        #step7: execute normalization\n",
    "        xhat = xmu * ivar\n",
    "\n",
    "        #step8: Nor the two transformation steps\n",
    "        gammax = gamma * xhat\n",
    "\n",
    "        #step9\n",
    "        out = gammax + beta\n",
    "\n",
    "        #store intermediate\n",
    "        self.cache = (xhat,gamma,xmu,ivar,sqrtvar,var,eps)\n",
    "        \n",
    "\n",
    "        return out\n",
    "    \n",
    "    def backward(self, dout):\n",
    "        #unfold the variables stored in cache\n",
    "        xhat,gamma,xmu,ivar,sqrtvar,var,eps = self.cache\n",
    "\n",
    "        #get the dimensions of the input/output\n",
    "        N,D = dout.shape\n",
    "\n",
    "        #step9\n",
    "        dbeta = np.sum(dout, axis=0)\n",
    "        dgammax = dout #not necessary, but more understandable\n",
    "\n",
    "        #step8\n",
    "        dgamma = np.sum(dgammax*xhat, axis=0)\n",
    "        dxhat = dgammax * gamma\n",
    "\n",
    "        #step7\n",
    "        divar = np.sum(dxhat*xmu, axis=0)\n",
    "        dxmu1 = dxhat * ivar\n",
    "\n",
    "        #step6\n",
    "        dsqrtvar = -1. /(sqrtvar**2) * divar\n",
    "\n",
    "        #step5\n",
    "        dvar = 0.5 * 1. /np.sqrt(var+eps) * dsqrtvar\n",
    "\n",
    "        #step4\n",
    "        dsq = 1. /N * np.ones((N,D)) * dvar\n",
    "\n",
    "        #step3\n",
    "        dxmu2 = 2 * xmu * dsq\n",
    "\n",
    "        #step2\n",
    "        dx1 = (dxmu1 + dxmu2)\n",
    "        dmu = -1 * np.sum(dxmu1+dxmu2, axis=0)\n",
    "\n",
    "        #step1\n",
    "        dx2 = 1. /N * np.ones((N,D)) * dmu\n",
    "\n",
    "        #step0\n",
    "        dx = dx1 + dx2\n",
    "\n",
    "        return dx, dgamma, dbeta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n",
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "# Create the data\n",
    "arr = np.arange(20).reshape(5, 4)\n",
    "gamma = 2\n",
    "beta = 1\n",
    "eps = 0.1\n",
    "\n",
    "# test both classes\n",
    "mybn = BatchNorm() # class of mine\n",
    "myout = mybn.forward(arr, gamma, beta, eps)\n",
    "mygrad_arr, mygrad_gamma, mygrad_beta = mybn.backward(myout)\n",
    "\n",
    "ttbn = BatchNormalization() # class of tutorial\n",
    "ttout = ttbn.forward(arr, gamma, beta, eps)\n",
    "ttgrad_arr, ttgrad_gamma, ttgrad_beta = mybn.backward(ttout)\n",
    "\n",
    "# make usre that both classes have the same outputs\n",
    "print(np.all(myout == ttout))\n",
    "print(np.all(mygrad_arr == ttgrad_arr))\n",
    "print(np.all(mygrad_beta == ttgrad_beta))\n",
    "print(np.all(mygrad_gamma == ttgrad_gamma))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "main",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
